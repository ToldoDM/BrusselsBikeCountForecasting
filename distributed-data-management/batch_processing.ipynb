{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Batch Processing\n",
    "## Goal\n",
    "Use Spark to compute the Pearson correlation coefficients.\n",
    "The task requires that for each timestamp between 2018-12-06 and 2023-03-31 to compute the correlation for each pair of sensors and (2) determine the top-5 pairs with the highest correlation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Common imports and Environment variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from itertools import combinations\n",
    "from pyspark.sql.functions import col, count, sum, first, mean, when\n",
    "from pyspark.sql.window import Window\n",
    "from tqdm import tqdm\n",
    "from pyspark import Row\n",
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--conf spark.ui.port=4040 ' + \\\n",
    "                                    '--conf spark.driver.memory=4g  pyspark-shell '"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spark session creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/07 20:51:26 WARN Utils: Your hostname, toldo-Victus resolves to a loopback address: 127.0.1.1; using 192.168.122.1 instead (on interface virbr0)\n",
      "23/05/07 20:51:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/07 20:51:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/07 20:51:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "             _c0        Date Time gap   Sensor Count Average speed\n0              0  2018-12-06        1    CAT17   0.0          -1.0\n1              1  2018-12-06        1  CB02411   0.0          -1.0\n2              2  2018-12-06        1   CB1101   0.0          -1.0\n3              3  2018-12-06        1   CB1142   0.0          -1.0\n4              4  2018-12-06        1   CB1143   0.0          -1.0\n...          ...         ...      ...      ...   ...           ...\n2725051  2725051  2023-03-31       96   CJE181   1.0           4.0\n2725052  2725052  2023-03-31       96    CJM90  10.0          17.0\n2725053  2725053  2023-03-31       96   CLW239   0.0          -1.0\n2725054  2725054  2023-03-31       96   COM205   2.0          13.0\n2725055  2725055  2023-03-31       96   CVT387   0.0          -1.0\n\n[2725056 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_c0</th>\n      <th>Date</th>\n      <th>Time gap</th>\n      <th>Sensor</th>\n      <th>Count</th>\n      <th>Average speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2018-12-06</td>\n      <td>1</td>\n      <td>CAT17</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2018-12-06</td>\n      <td>1</td>\n      <td>CB02411</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2018-12-06</td>\n      <td>1</td>\n      <td>CB1101</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2018-12-06</td>\n      <td>1</td>\n      <td>CB1142</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2018-12-06</td>\n      <td>1</td>\n      <td>CB1143</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2725051</th>\n      <td>2725051</td>\n      <td>2023-03-31</td>\n      <td>96</td>\n      <td>CJE181</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2725052</th>\n      <td>2725052</td>\n      <td>2023-03-31</td>\n      <td>96</td>\n      <td>CJM90</td>\n      <td>10.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>2725053</th>\n      <td>2725053</td>\n      <td>2023-03-31</td>\n      <td>96</td>\n      <td>CLW239</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2725054</th>\n      <td>2725054</td>\n      <td>2023-03-31</td>\n      <td>96</td>\n      <td>COM205</td>\n      <td>2.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>2725055</th>\n      <td>2725055</td>\n      <td>2023-03-31</td>\n      <td>96</td>\n      <td>CVT387</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2725056 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Spark session\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"pearson_coefficient_batch\").getOrCreate()\n",
    "\n",
    "# Get Spark context\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "#Read csv and create a Spark dataframe\n",
    "df = spark.read.option(\"header\", True).csv(\"data.csv\")\n",
    "\n",
    "#Nicer way to show but takes little more time\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cell is used to pivot the dataframe. The cell calculate a pivoted dataframe with a column for each sensor, and a list of all the combination of sensors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "       CAT17_Count CB02411_Count CB1101_Count CB1142_Count CB1143_Count   \n0              0.0           0.0          0.0          0.0          0.0  \\\n1              0.0           0.0          0.0          0.0          0.0   \n2              0.0           0.0          0.0          0.0          0.0   \n3              0.0           0.0          0.0          0.0          0.0   \n4              0.0           0.0          0.0          0.0          0.0   \n...            ...           ...          ...          ...          ...   \n151387         4.0           5.0         15.0          7.0          5.0   \n151388         3.0           5.0         14.0          2.0          6.0   \n151389         1.0           1.0         17.0          5.0          5.0   \n151390         1.0           5.0         10.0          3.0          6.0   \n151391         2.0           6.0         11.0          6.0          4.0   \n\n       CB1599_Count CB1699_Count CB2105_Count CEE016_Count CEK049_Count   \n0               0.0          0.0          0.0          0.0          0.0  \\\n1               0.0          0.0          0.0          0.0          0.0   \n2               0.0          0.0          0.0          0.0          0.0   \n3               0.0          0.0          0.0          0.0          0.0   \n4               0.0          0.0          0.0          0.0          0.0   \n...             ...          ...          ...          ...          ...   \n151387          1.0          1.0          9.0          6.0         10.0   \n151388          0.0          1.0          7.0          2.0          5.0   \n151389          0.0          1.0          7.0          3.0          7.0   \n151390          2.0          4.0         13.0          0.0          4.0   \n151391          2.0          2.0          5.0          5.0          4.0   \n\n       CEK18_Count CEK31_Count CEV011_Count CJE181_Count CJM90_Count   \n0              0.0         0.0          0.0          0.0         0.0  \\\n1              0.0         0.0          0.0          0.0         0.0   \n2              0.0         0.0          0.0          0.0         0.0   \n3              0.0         0.0          0.0          0.0         0.0   \n4              0.0         0.0          0.0          0.0         0.0   \n...            ...         ...          ...          ...         ...   \n151387         2.0         4.0          3.0          0.0        20.0   \n151388         2.0         1.0          1.0          1.0        14.0   \n151389         3.0         4.0          0.0          0.0        12.0   \n151390         1.0         2.0          0.0          0.0        16.0   \n151391         2.0         4.0          2.0          1.0        10.0   \n\n       CLW239_Count COM205_Count CVT387_Count        Date  Time gap  \n0               0.0          0.0          0.0  2018-12-06         1  \n1               0.0          0.0          0.0  2018-12-06         2  \n2               0.0          0.0          0.0  2018-12-06         3  \n3               0.0          0.0          0.0  2018-12-06         4  \n4               0.0          0.0          0.0  2018-12-06         5  \n...             ...          ...          ...         ...       ...  \n151387          0.0          0.0          0.0  2023-03-31        92  \n151388          0.0          2.0          0.0  2023-03-31        93  \n151389          0.0          3.0          1.0  2023-03-31        94  \n151390          0.0          0.0          0.0  2023-03-31        95  \n151391          0.0          2.0          0.0  2023-03-31        96  \n\n[151392 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAT17_Count</th>\n      <th>CB02411_Count</th>\n      <th>CB1101_Count</th>\n      <th>CB1142_Count</th>\n      <th>CB1143_Count</th>\n      <th>CB1599_Count</th>\n      <th>CB1699_Count</th>\n      <th>CB2105_Count</th>\n      <th>CEE016_Count</th>\n      <th>CEK049_Count</th>\n      <th>CEK18_Count</th>\n      <th>CEK31_Count</th>\n      <th>CEV011_Count</th>\n      <th>CJE181_Count</th>\n      <th>CJM90_Count</th>\n      <th>CLW239_Count</th>\n      <th>COM205_Count</th>\n      <th>CVT387_Count</th>\n      <th>Date</th>\n      <th>Time gap</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018-12-06</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018-12-06</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018-12-06</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018-12-06</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018-12-06</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>151387</th>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>15.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2023-03-31</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>151388</th>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>14.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2023-03-31</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>151389</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>17.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2023-03-31</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>151390</th>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2023-03-31</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>151391</th>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2023-03-31</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n<p>151392 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot the dataframe\n",
    "pivot_df = df.groupBy(\"Date\", \"Time gap\").pivot(\"Sensor\").agg(first(\"Count\").alias(\"Count\"),\n",
    "                                                              first(\"Average speed\").alias(\"Average speed\"))\n",
    "\n",
    "#Sort by date and time gap\n",
    "pivot_df = pivot_df.withColumn(\"Time gap\", col(\"Time gap\").cast(\"int\")).sort(\"Date\", \"Time gap\")\n",
    "\n",
    "# Store all columns names\n",
    "columns = pivot_df.columns\n",
    "\n",
    "# Store only \"count\" columns and timestamp\n",
    "count_columns = [c for c in columns if c.endswith(\"_Count\")]\n",
    "# Create all possible combinations of sensors\n",
    "pairs = list(combinations(count_columns, 2))\n",
    "\n",
    "# Keep timestamp\n",
    "count_columns.append(\"Date\")\n",
    "count_columns.append(\"Time gap\")\n",
    "\n",
    "# Filter out the dataframe to only keep those\n",
    "filter_df = pivot_df.select(count_columns)\n",
    "\n",
    "#Nicer way to show but takes little more time\n",
    "filter_df.toPandas()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method is used to calculate the Pearson coefficient between two sensors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define the function to calculate Pearson correlation coefficient with time component\n",
    "def pearson_corr_coeff_time(count_df, i, j):\n",
    "    # Assuming i and j are the names of two columns\n",
    "    col_i = col(i)\n",
    "    col_j = col(j)\n",
    "\n",
    "    # We define the window function to take in consideration all the data from the current line to the beginning\n",
    "    w = Window.rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "    # Compute the window function count for column i and j\n",
    "    ci_count = count(i).over(w)\n",
    "    cj_count = count(j).over(w)\n",
    "\n",
    "    # Use a sub-query to calculate the various column needed for the calculation of the Pearson coefficient\n",
    "    # We modify the name of the sensor column to i and j\n",
    "    subquery = count_df.select('Date', 'Time gap', col_i.alias('i'), col_j.alias('j'),\n",
    "                               ci_count.alias('ci_count'),\n",
    "                               cj_count.alias('cj_count'))\n",
    "    # We define columns that are the sum of the passage of bikes of the sensor i/j\n",
    "    subquery = subquery.select('Date', 'Time gap', 'i', 'j', sum('i').over(w).alias('ci_total'),\n",
    "                               sum('j').over(w).alias('cj_total'), 'ci_count', 'cj_count')\n",
    "    # We define columns that are the mean of the sensor i/j\n",
    "    subquery = subquery.select('Date', 'Time gap', 'i', 'j', 'ci_total', 'cj_total', 'ci_count', 'cj_count',\n",
    "                               (col('ci_total') / col('ci_count')).alias('ci_mean'),\n",
    "                               (col('cj_total') / col('cj_count')).alias('cj_mean'))\n",
    "    # We define columns that are the numerator and the two part of the denominator of the Pearson coefficient formula\n",
    "    subquery = subquery.select('Date', 'Time gap', 'i', 'j', 'ci_total', 'cj_total', 'ci_count', 'cj_count', 'ci_mean',\n",
    "                               'cj_mean',\n",
    "                               (sum((col('i') - col('ci_mean')) * (col('j') - col('cj_mean'))).over(w)).alias(\n",
    "                                   'numerator'),\n",
    "                               ((sum((col('i') - col('ci_mean')) ** 2).over(w)) ** 0.5).alias('den1'),\n",
    "                               ((sum((col('j') - col('cj_mean')) ** 2).over(w)) ** 0.5).alias('den2'))\n",
    "\n",
    "    # Compute the Pearson correlation coefficient for each date and time gap\n",
    "    rij = subquery.select(\"Date\", \"Time gap\",\n",
    "                          when((col(\"den1\") == 0) | (col(\"den2\") == 0), 0).otherwise(\n",
    "                              col(\"numerator\") / (col(\"den1\") * col(\"den2\"))))\n",
    "\n",
    "    # Renaming columns for clarity\n",
    "    i = i.rstrip(\"_Count\")\n",
    "    j = j.rstrip(\"_Count\")\n",
    "    rij = rij.withColumnRenamed(rij.columns[2], i + \"_\" + j)\n",
    "\n",
    "    return rij"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The following cells are distributed like this otherwise spark crashes if you try all in one go.**\n",
    "\n",
    "Now we get the last value of each sensor pair."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.51s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "rij_dict = {}\n",
    "for pair in tqdm(pairs[:20]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:28<00:00,  1.43s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[20:40]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:26<00:00,  1.33s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[40:60]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:25<00:00,  1.26s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[60:80]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:25<00:00,  1.27s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[80:100]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:28<00:00,  1.42s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[100:120]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:28<00:00,  1.44s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[120:140]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  1.34s/it]                                 \n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(pairs[140:]):\n",
    "    rij = pearson_corr_coeff_time(filter_df, pair[0], pair[1])\n",
    "    last_row = spark.createDataFrame(rij.tail(1))\n",
    "    for i in last_row.collect():\n",
    "        rij_dict[last_row.columns[2]] = i[last_row.columns[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create a spark Dataframe with all the values collected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   CAT17_CB02411  CAT17_CB1101  CAT17_CB1142  CAT17_CB1143  CAT17_CB1599   \n0       0.630942      0.166352      0.605473      0.555556      0.649392  \\\n\n   CAT17_CB1699  CAT17_CB2105  CAT17_CEE016  CAT17_CEK049  CAT17_CEK18  ...   \n0      0.726944      0.679482      0.666109       0.69159     0.446886  ...  \\\n\n   CJE181_CJM90  CJE181_CLW239  CJE181_COM205  CJE181_CVT387  CJM90_CLW239   \n0      0.628205        0.61882        0.46584       0.701515      0.693832  \\\n\n   CJM90_COM205  CJM90_CVT387  CLW239_COM205  CLW239_CVT387  COM205_CVT387  \n0      0.643247      0.679343       0.659451       0.663279       0.519127  \n\n[1 rows x 153 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAT17_CB02411</th>\n      <th>CAT17_CB1101</th>\n      <th>CAT17_CB1142</th>\n      <th>CAT17_CB1143</th>\n      <th>CAT17_CB1599</th>\n      <th>CAT17_CB1699</th>\n      <th>CAT17_CB2105</th>\n      <th>CAT17_CEE016</th>\n      <th>CAT17_CEK049</th>\n      <th>CAT17_CEK18</th>\n      <th>...</th>\n      <th>CJE181_CJM90</th>\n      <th>CJE181_CLW239</th>\n      <th>CJE181_COM205</th>\n      <th>CJE181_CVT387</th>\n      <th>CJM90_CLW239</th>\n      <th>CJM90_COM205</th>\n      <th>CJM90_CVT387</th>\n      <th>CLW239_COM205</th>\n      <th>CLW239_CVT387</th>\n      <th>COM205_CVT387</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.630942</td>\n      <td>0.166352</td>\n      <td>0.605473</td>\n      <td>0.555556</td>\n      <td>0.649392</td>\n      <td>0.726944</td>\n      <td>0.679482</td>\n      <td>0.666109</td>\n      <td>0.69159</td>\n      <td>0.446886</td>\n      <td>...</td>\n      <td>0.628205</td>\n      <td>0.61882</td>\n      <td>0.46584</td>\n      <td>0.701515</td>\n      <td>0.693832</td>\n      <td>0.643247</td>\n      <td>0.679343</td>\n      <td>0.659451</td>\n      <td>0.663279</td>\n      <td>0.519127</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 153 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_rj_df = spark.createDataFrame(Row(rij_dict))\n",
    "pdf = last_rj_df.toPandas()\n",
    "pdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transpose the Dataframe taking only the top 5 row, so is more readable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                      0\nCB2105_CJM90   0.835246\nCB2105_CEK049  0.817282\nCEK049_CJM90   0.813338\nCB1599_CEK049  0.808896\nCAT17_CVT387   0.798508",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CB2105_CJM90</th>\n      <td>0.835246</td>\n    </tr>\n    <tr>\n      <th>CB2105_CEK049</th>\n      <td>0.817282</td>\n    </tr>\n    <tr>\n      <th>CEK049_CJM90</th>\n      <td>0.813338</td>\n    </tr>\n    <tr>\n      <th>CB1599_CEK049</th>\n      <td>0.808896</td>\n    </tr>\n    <tr>\n      <th>CAT17_CVT387</th>\n      <td>0.798508</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.T.nlargest(5, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
